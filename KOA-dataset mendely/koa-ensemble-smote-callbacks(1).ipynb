{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install efficientnet\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-22T10:47:31.848720Z","iopub.execute_input":"2023-06-22T10:47:31.849205Z","iopub.status.idle":"2023-06-22T10:47:46.582239Z","shell.execute_reply.started":"2023-06-22T10:47:31.849164Z","shell.execute_reply":"2023-06-22T10:47:46.580976Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet) (0.20.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.23.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.8.0)\nRequirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.10.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (3.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (9.5.0)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2.28.1)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2023.4.12)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.4.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (21.3)\nRequirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->scikit-image->efficientnet) (3.0.9)\nInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.1 keras-applications-1.0.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import ModelCheckpoint, Callback\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom efficientnet.keras import EfficientNetB4, EfficientNetB5, EfficientNetB6\nfrom keras.applications.densenet import DenseNet201\nfrom imblearn.over_sampling import SMOTE","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:47:46.584965Z","iopub.execute_input":"2023-06-22T10:47:46.586543Z","iopub.status.idle":"2023-06-22T10:47:58.493604Z","shell.execute_reply.started":"2023-06-22T10:47:46.586509Z","shell.execute_reply":"2023-06-22T10:47:58.492558Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"class MyCallback(Callback):\n    def __init__(self, model, patience, stop_patience, threshold, factor, batches, epochs, ask_epoch):\n        super(MyCallback, self).__init__()\n        self.model = model\n        self.patience = patience\n        self.stop_patience = stop_patience\n        self.threshold = threshold\n        self.factor = factor\n        self.batches = batches\n        self.epochs = epochs\n        self.ask_epoch = ask_epoch\n        self.ask_epoch_initial = ask_epoch\n\n        self.count = 0\n        self.stop_count = 0\n        self.best_epoch = 1\n        self.initial_lr = float(tf.keras.backend.get_value(model.optimizer.lr))\n        self.highest_tracc = 0.0\n        self.lowest_vloss = np.inf\n        self.best_weights = self.model.get_weights()\n        self.initial_weights = self.model.get_weights()\n\n    def on_epoch_end(self, epoch, logs=None):\n        if epoch % self.batches == 0 and epoch > 0:\n            tr_acc = logs.get('accuracy')\n            v_loss = logs.get('val_loss')\n\n            if tr_acc > self.highest_tracc:\n                self.highest_tracc = tr_acc\n\n            if v_loss < self.lowest_vloss:\n                self.lowest_vloss = v_loss\n                self.best_epoch = epoch + 1\n                self.best_weights = self.model.get_weights()\n                self.count = 0\n            else:\n                self.count += 1\n\n            if tr_acc >= self.threshold:\n                self.ask_epoch -= 1\n\n            if self.count == self.patience and self.ask_epoch > 0:\n                print(\"\\nEpoch %d: Accuracy threshold reached. Decreasing learning rate.\" % (epoch + 1))\n                old_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n                new_lr = old_lr * self.factor\n                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)\n                print(\"Learning rate decreased from %f to %f\" % (old_lr, new_lr))\n                self.count = 0\n\n            if self.count == self.patience and self.ask_epoch == 0:\n                self.stop_count += 1\n                if self.stop_count == self.stop_patience:\n                    print(\"\\nTraining stopped at epoch %d\" % (epoch + 1))\n                    self.model.stop_training = True\n                else:\n                    print(\"\\nEpoch %d: Learning rate adjustment limit reached. Restoring best weights.\" % (epoch + 1))\n                    self.model.set_weights(self.best_weights)\n                    self.count = 0","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:47:58.495299Z","iopub.execute_input":"2023-06-22T10:47:58.496072Z","iopub.status.idle":"2023-06-22T10:47:58.515219Z","shell.execute_reply.started":"2023-06-22T10:47:58.496034Z","shell.execute_reply":"2023-06-22T10:47:58.514279Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Set the data path and categories\ndata_path = '/kaggle/input/koa-1500/MedicalExpert-I'\ncategories = os.listdir(data_path)\n\n# Assign labels to the categories\nlabels = [i for i in range(len(categories))]\nlabel_dict = dict(zip(categories, labels))\n\nimg_size = 160\ndata = []\ntarget = []\n\n# Load the image data and labels\nfor category in categories:\n    folder_path = os.path.join(data_path, category)\n    img_names = os.listdir(folder_path)\n\n    for img_name in img_names:\n        img_path = os.path.join(folder_path, img_name)\n        img = cv2.imread(img_path)\n\n        try:\n            # Convert the image to grayscale\n            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            # Convert the grayscale image to RGB by replicating the single channel three times\n            rgb_img = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB)\n            # Resize the image to the desired size\n            resized_img = cv2.resize(rgb_img, (img_size, img_size))\n            # Normalize the image\n            normalized_img = resized_img / 255.0\n            # Append the image and its corresponding label to the data and target lists\n            data.append(normalized_img)\n            target.append(label_dict[category])\n\n        except Exception as e:\n            print('Exception:', e)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:47:58.517481Z","iopub.execute_input":"2023-06-22T10:47:58.517774Z","iopub.status.idle":"2023-06-22T10:48:11.920629Z","shell.execute_reply.started":"2023-06-22T10:47:58.517749Z","shell.execute_reply":"2023-06-22T10:48:11.919147Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Convert the data and target lists to numpy arrays\ndata = np.array(data, dtype='float32')\ntarget = np.array(target)\n\n# Apply SMOTE oversampling to the data\nsmote = SMOTE(random_state=42)\ndata_res, target_res = smote.fit_resample(data.reshape(data.shape[0], -1), target)\ndata_res = data_res.reshape(data_res.shape[0], img_size, img_size, 3)\ntarget_res = np_utils.to_categorical(target_res)\n\n# Split the data into training, validation, and testing sets\nx_train, x_test, y_train, y_test = train_test_split(data_res, target_res, test_size=0.2, random_state=42)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n\n# Ensemble models\nbase_models = [\n    EfficientNetB4(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3), pooling='max'),\n    EfficientNetB5(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3), pooling='max'),\n    EfficientNetB6(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3), pooling='max'),\n]\n\nfrom keras.layers import Input, concatenate\n\n# Initialize the ensemble model\nensemble_input = Input(shape=(img_size, img_size, 3))\nensemble_outputs = []\n\n# Add the base models to the ensemble model\nfor base_model in base_models:\n    base_model_output = base_model(ensemble_input)\n    ensemble_outputs.append(base_model_output)\n\n# Concatenate the outputs of the base models\nensemble_outputs = concatenate(ensemble_outputs)\n\n# Add BatchNormalization and Dense layers to the ensemble model\nx = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(ensemble_outputs)\nx = Dense(256, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),\n          bias_regularizer=regularizers.l1(0.006), activation='relu')(x)\nx = Dropout(rate=0.45, seed=123)(x)\nensemble_output = Dense(len(categories), activation='softmax')(x)\n\n# Create the ensemble model\nmodel = tf.keras.models.Model(inputs=[ensemble_input], outputs=[ensemble_output])\n\nmodel.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:48:11.922575Z","iopub.execute_input":"2023-06-22T10:48:11.922991Z","iopub.status.idle":"2023-06-22T10:48:54.628059Z","shell.execute_reply.started":"2023-06-22T10:48:11.922946Z","shell.execute_reply":"2023-06-22T10:48:54.627148Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b4_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n71892840/71892840 [==============================] - 1s 0us/step\nDownloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b5_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n115515256/115515256 [==============================] - 1s 0us/step\nDownloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b6_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n165527152/165527152 [==============================] - 3s 0us/step\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_4 (InputLayer)           [(None, 160, 160, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n efficientnet-b4 (Functional)   (None, 1792)         17673816    ['input_4[0][0]']                \n                                                                                                  \n efficientnet-b5 (Functional)   (None, 2048)         28513520    ['input_4[0][0]']                \n                                                                                                  \n efficientnet-b6 (Functional)   (None, 2304)         40960136    ['input_4[0][0]']                \n                                                                                                  \n concatenate (Concatenate)      (None, 6144)         0           ['efficientnet-b4[0][0]',        \n                                                                  'efficientnet-b5[0][0]',        \n                                                                  'efficientnet-b6[0][0]']        \n                                                                                                  \n batch_normalization (BatchNorm  (None, 6144)        24576       ['concatenate[0][0]']            \n alization)                                                                                       \n                                                                                                  \n dense (Dense)                  (None, 256)          1573120     ['batch_normalization[0][0]']    \n                                                                                                  \n dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n                                                                                                  \n dense_1 (Dense)                (None, 5)            1285        ['dropout[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 88,746,453\nTrainable params: 88,211,797\nNon-trainable params: 534,656\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the callbacks\nif os.path.exists('/kaggle/working/best_model.h5'):\n    os.remove('/kaggle/working/best_model.h5')\ncheckpoint = ModelCheckpoint('/kaggle/working/best_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\nmy_callback = MyCallback(model=model, patience=10, stop_patience=5, threshold=0.9, factor=0.1, batches=10, epochs=100, ask_epoch=10)\n\n# Train the model\nhistory = model.fit(x_train, y_train, batch_size=10, epochs=100, validation_data=(x_val, y_val), callbacks=[my_callback])","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:48:54.631593Z","iopub.execute_input":"2023-06-22T10:48:54.633712Z","iopub.status.idle":"2023-06-22T13:25:32.935328Z","shell.execute_reply.started":"2023-06-22T10:48:54.633672Z","shell.execute_reply":"2023-06-22T13:25:32.934212Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2023-06-22 10:51:51.169835: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/efficientnet-b4/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"155/155 [==============================] - 473s 667ms/step - loss: 10.7401 - accuracy: 0.4734 - val_loss: 9.8908 - val_accuracy: 0.4436\nEpoch 2/100\n155/155 [==============================] - 88s 569ms/step - loss: 8.9863 - accuracy: 0.6284 - val_loss: 8.2919 - val_accuracy: 0.5875\nEpoch 3/100\n155/155 [==============================] - 87s 564ms/step - loss: 6.4858 - accuracy: 0.7918 - val_loss: 6.0853 - val_accuracy: 0.7957\nEpoch 5/100\n155/155 [==============================] - 87s 564ms/step - loss: 5.5803 - accuracy: 0.8178 - val_loss: 5.2573 - val_accuracy: 0.8093\nEpoch 6/100\n155/155 [==============================] - 91s 590ms/step - loss: 4.7366 - accuracy: 0.8547 - val_loss: 4.4125 - val_accuracy: 0.8521\nEpoch 7/100\n155/155 [==============================] - 91s 590ms/step - loss: 4.0407 - accuracy: 0.8794 - val_loss: 3.8964 - val_accuracy: 0.8463\nEpoch 8/100\n155/155 [==============================] - 88s 566ms/step - loss: 3.4682 - accuracy: 0.8794 - val_loss: 3.4055 - val_accuracy: 0.8463\nEpoch 9/100\n155/155 [==============================] - 91s 588ms/step - loss: 2.9150 - accuracy: 0.9163 - val_loss: 2.8877 - val_accuracy: 0.8560\nEpoch 10/100\n155/155 [==============================] - 91s 588ms/step - loss: 2.4750 - accuracy: 0.9202 - val_loss: 2.5247 - val_accuracy: 0.8580\nEpoch 11/100\n155/155 [==============================] - 92s 594ms/step - loss: 2.0870 - accuracy: 0.9390 - val_loss: 2.1406 - val_accuracy: 0.8677\nEpoch 12/100\n155/155 [==============================] - 91s 588ms/step - loss: 1.7859 - accuracy: 0.9390 - val_loss: 1.8835 - val_accuracy: 0.8658\nEpoch 13/100\n155/155 [==============================] - 91s 590ms/step - loss: 1.5456 - accuracy: 0.9403 - val_loss: 1.6852 - val_accuracy: 0.8658\nEpoch 14/100\n155/155 [==============================] - 88s 565ms/step - loss: 1.3545 - accuracy: 0.9423 - val_loss: 1.5336 - val_accuracy: 0.8541\nEpoch 15/100\n155/155 [==============================] - 91s 587ms/step - loss: 1.1720 - accuracy: 0.9488 - val_loss: 1.4145 - val_accuracy: 0.8580\nEpoch 16/100\n155/155 [==============================] - 91s 587ms/step - loss: 1.0624 - accuracy: 0.9442 - val_loss: 1.2216 - val_accuracy: 0.8716\nEpoch 17/100\n155/155 [==============================] - 91s 587ms/step - loss: 0.9413 - accuracy: 0.9611 - val_loss: 1.1961 - val_accuracy: 0.8521\nEpoch 18/100\n155/155 [==============================] - 88s 564ms/step - loss: 0.8865 - accuracy: 0.9351 - val_loss: 1.0874 - val_accuracy: 0.8288\nEpoch 19/100\n155/155 [==============================] - 91s 589ms/step - loss: 0.8279 - accuracy: 0.9371 - val_loss: 1.0362 - val_accuracy: 0.8444\nEpoch 20/100\n155/155 [==============================] - 91s 589ms/step - loss: 0.7902 - accuracy: 0.9313 - val_loss: 1.0442 - val_accuracy: 0.8560\nEpoch 21/100\n155/155 [==============================] - 92s 592ms/step - loss: 0.7491 - accuracy: 0.9416 - val_loss: 1.0498 - val_accuracy: 0.8424\nEpoch 22/100\n155/155 [==============================] - 91s 587ms/step - loss: 0.7090 - accuracy: 0.9377 - val_loss: 0.9361 - val_accuracy: 0.8599\nEpoch 23/100\n155/155 [==============================] - 91s 587ms/step - loss: 0.6447 - accuracy: 0.9540 - val_loss: 0.9566 - val_accuracy: 0.8541\nEpoch 24/100\n155/155 [==============================] - 91s 586ms/step - loss: 0.6102 - accuracy: 0.9540 - val_loss: 0.8940 - val_accuracy: 0.8463\nEpoch 25/100\n155/155 [==============================] - 91s 588ms/step - loss: 0.5706 - accuracy: 0.9624 - val_loss: 0.9067 - val_accuracy: 0.8502\nEpoch 26/100\n155/155 [==============================] - 91s 588ms/step - loss: 0.5477 - accuracy: 0.9591 - val_loss: 0.8191 - val_accuracy: 0.8716\nEpoch 27/100\n155/155 [==============================] - 87s 564ms/step - loss: 0.5398 - accuracy: 0.9533 - val_loss: 0.9157 - val_accuracy: 0.8385\nEpoch 28/100\n155/155 [==============================] - 91s 586ms/step - loss: 0.5392 - accuracy: 0.9553 - val_loss: 0.8140 - val_accuracy: 0.8580\nEpoch 29/100\n155/155 [==============================] - 87s 563ms/step - loss: 0.5540 - accuracy: 0.9403 - val_loss: 0.8050 - val_accuracy: 0.8677\nEpoch 30/100\n155/155 [==============================] - 91s 587ms/step - loss: 0.4800 - accuracy: 0.9715 - val_loss: 0.7594 - val_accuracy: 0.8891\nEpoch 31/100\n155/155 [==============================] - 92s 593ms/step - loss: 0.4736 - accuracy: 0.9676 - val_loss: 0.7273 - val_accuracy: 0.8735\nEpoch 32/100\n155/155 [==============================] - 87s 563ms/step - loss: 0.4828 - accuracy: 0.9514 - val_loss: 0.6620 - val_accuracy: 0.8949\nEpoch 33/100\n155/155 [==============================] - 87s 562ms/step - loss: 0.4533 - accuracy: 0.9663 - val_loss: 0.6885 - val_accuracy: 0.8852\nEpoch 34/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.4036 - accuracy: 0.9773 - val_loss: 0.7096 - val_accuracy: 0.8794\nEpoch 35/100\n155/155 [==============================] - 91s 588ms/step - loss: 0.3593 - accuracy: 0.9851 - val_loss: 0.6802 - val_accuracy: 0.8774\nEpoch 36/100\n155/155 [==============================] - 87s 563ms/step - loss: 0.3580 - accuracy: 0.9812 - val_loss: 0.7245 - val_accuracy: 0.8774\nEpoch 37/100\n155/155 [==============================] - 91s 588ms/step - loss: 0.3648 - accuracy: 0.9812 - val_loss: 0.7376 - val_accuracy: 0.8872\nEpoch 38/100\n155/155 [==============================] - 87s 562ms/step - loss: 0.3455 - accuracy: 0.9799 - val_loss: 0.6425 - val_accuracy: 0.8891\nEpoch 39/100\n155/155 [==============================] - 91s 586ms/step - loss: 0.3377 - accuracy: 0.9818 - val_loss: 0.6868 - val_accuracy: 0.8852\nEpoch 40/100\n155/155 [==============================] - 87s 564ms/step - loss: 0.3381 - accuracy: 0.9767 - val_loss: 0.7058 - val_accuracy: 0.8735\nEpoch 41/100\n155/155 [==============================] - 88s 569ms/step - loss: 0.3148 - accuracy: 0.9857 - val_loss: 0.6576 - val_accuracy: 0.8716\nEpoch 42/100\n155/155 [==============================] - 87s 561ms/step - loss: 0.3507 - accuracy: 0.9637 - val_loss: 0.7213 - val_accuracy: 0.8794\nEpoch 43/100\n155/155 [==============================] - 91s 586ms/step - loss: 0.3821 - accuracy: 0.9637 - val_loss: 0.7130 - val_accuracy: 0.8735\nEpoch 44/100\n155/155 [==============================] - 91s 586ms/step - loss: 0.3839 - accuracy: 0.9617 - val_loss: 0.6976 - val_accuracy: 0.8813\nEpoch 45/100\n155/155 [==============================] - 91s 587ms/step - loss: 0.3232 - accuracy: 0.9825 - val_loss: 0.7301 - val_accuracy: 0.8560\nEpoch 46/100\n155/155 [==============================] - 87s 562ms/step - loss: 0.3416 - accuracy: 0.9728 - val_loss: 0.6700 - val_accuracy: 0.8755\nEpoch 47/100\n155/155 [==============================] - 87s 562ms/step - loss: 0.3455 - accuracy: 0.9721 - val_loss: 0.6572 - val_accuracy: 0.8852\nEpoch 48/100\n155/155 [==============================] - 91s 586ms/step - loss: 0.3471 - accuracy: 0.9721 - val_loss: 0.6826 - val_accuracy: 0.8891\nEpoch 49/100\n155/155 [==============================] - 87s 562ms/step - loss: 0.3422 - accuracy: 0.9689 - val_loss: 0.6999 - val_accuracy: 0.8813\nEpoch 50/100\n155/155 [==============================] - 87s 564ms/step - loss: 0.3345 - accuracy: 0.9760 - val_loss: 0.6773 - val_accuracy: 0.8813\nEpoch 51/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.3179 - accuracy: 0.9786 - val_loss: 0.7501 - val_accuracy: 0.8891\nEpoch 52/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.3171 - accuracy: 0.9786 - val_loss: 0.7027 - val_accuracy: 0.8696\nEpoch 53/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.3216 - accuracy: 0.9741 - val_loss: 0.7166 - val_accuracy: 0.8735\nEpoch 54/100\n155/155 [==============================] - 91s 587ms/step - loss: 0.3376 - accuracy: 0.9695 - val_loss: 0.7811 - val_accuracy: 0.8638\nEpoch 55/100\n155/155 [==============================] - 91s 587ms/step - loss: 0.3454 - accuracy: 0.9721 - val_loss: 0.6946 - val_accuracy: 0.8755\nEpoch 56/100\n155/155 [==============================] - 87s 562ms/step - loss: 0.3124 - accuracy: 0.9805 - val_loss: 0.7243 - val_accuracy: 0.8930\nEpoch 57/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.3329 - accuracy: 0.9682 - val_loss: 0.6763 - val_accuracy: 0.8852\nEpoch 58/100\n155/155 [==============================] - 87s 561ms/step - loss: 0.3246 - accuracy: 0.9734 - val_loss: 0.7164 - val_accuracy: 0.8813\nEpoch 59/100\n155/155 [==============================] - 91s 587ms/step - loss: 0.3094 - accuracy: 0.9825 - val_loss: 0.7030 - val_accuracy: 0.8852\nEpoch 60/100\n155/155 [==============================] - 87s 564ms/step - loss: 0.3298 - accuracy: 0.9767 - val_loss: 0.7004 - val_accuracy: 0.8735\nEpoch 61/100\n155/155 [==============================] - 88s 568ms/step - loss: 0.2870 - accuracy: 0.9844 - val_loss: 0.6564 - val_accuracy: 0.8911\nEpoch 62/100\n155/155 [==============================] - 91s 586ms/step - loss: 0.2656 - accuracy: 0.9890 - val_loss: 0.7279 - val_accuracy: 0.8619\nEpoch 63/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.2701 - accuracy: 0.9870 - val_loss: 0.6477 - val_accuracy: 0.8813\nEpoch 64/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.2550 - accuracy: 0.9883 - val_loss: 0.6380 - val_accuracy: 0.8969\nEpoch 65/100\n155/155 [==============================] - 87s 563ms/step - loss: 0.2686 - accuracy: 0.9838 - val_loss: 0.7115 - val_accuracy: 0.8794\nEpoch 66/100\n155/155 [==============================] - 87s 563ms/step - loss: 0.2566 - accuracy: 0.9896 - val_loss: 0.6719 - val_accuracy: 0.8852\nEpoch 67/100\n155/155 [==============================] - 90s 584ms/step - loss: 0.2647 - accuracy: 0.9864 - val_loss: 0.6775 - val_accuracy: 0.8872\nEpoch 68/100\n155/155 [==============================] - 87s 561ms/step - loss: 0.2413 - accuracy: 0.9890 - val_loss: 0.6299 - val_accuracy: 0.8774\nEpoch 69/100\n155/155 [==============================] - 87s 562ms/step - loss: 0.2400 - accuracy: 0.9916 - val_loss: 0.7052 - val_accuracy: 0.8794\nEpoch 70/100\n155/155 [==============================] - 87s 563ms/step - loss: 0.2380 - accuracy: 0.9903 - val_loss: 0.6651 - val_accuracy: 0.8891\nEpoch 71/100\n155/155 [==============================] - 88s 568ms/step - loss: 0.2283 - accuracy: 0.9903 - val_loss: 0.6350 - val_accuracy: 0.8794\nEpoch 72/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.2512 - accuracy: 0.9864 - val_loss: 0.6477 - val_accuracy: 0.8852\nEpoch 73/100\n155/155 [==============================] - 87s 562ms/step - loss: 0.2554 - accuracy: 0.9838 - val_loss: 0.6395 - val_accuracy: 0.8774\nEpoch 74/100\n155/155 [==============================] - 91s 587ms/step - loss: 0.2314 - accuracy: 0.9916 - val_loss: 0.6877 - val_accuracy: 0.8677\nEpoch 75/100\n155/155 [==============================] - 91s 587ms/step - loss: 0.2122 - accuracy: 0.9942 - val_loss: 0.6165 - val_accuracy: 0.8833\nEpoch 76/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.2133 - accuracy: 0.9916 - val_loss: 0.6318 - val_accuracy: 0.8833\nEpoch 77/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.2346 - accuracy: 0.9844 - val_loss: 0.6312 - val_accuracy: 0.8891\nEpoch 78/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.2337 - accuracy: 0.9870 - val_loss: 0.6042 - val_accuracy: 0.8891\nEpoch 79/100\n155/155 [==============================] - 91s 588ms/step - loss: 0.2168 - accuracy: 0.9922 - val_loss: 0.6477 - val_accuracy: 0.8969\nEpoch 80/100\n155/155 [==============================] - 91s 588ms/step - loss: 0.2412 - accuracy: 0.9844 - val_loss: 0.6412 - val_accuracy: 0.8833\nEpoch 81/100\n155/155 [==============================] - 88s 569ms/step - loss: 0.2152 - accuracy: 0.9890 - val_loss: 0.5770 - val_accuracy: 0.8969\nEpoch 82/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.2125 - accuracy: 0.9916 - val_loss: 0.6254 - val_accuracy: 0.9027\nEpoch 83/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.2011 - accuracy: 0.9942 - val_loss: 0.6021 - val_accuracy: 0.8911\nEpoch 84/100\n155/155 [==============================] - 87s 562ms/step - loss: 0.2027 - accuracy: 0.9922 - val_loss: 0.6246 - val_accuracy: 0.8930\nEpoch 85/100\n155/155 [==============================] - 91s 587ms/step - loss: 0.1922 - accuracy: 0.9942 - val_loss: 0.6499 - val_accuracy: 0.8949\nEpoch 86/100\n155/155 [==============================] - 87s 561ms/step - loss: 0.2064 - accuracy: 0.9916 - val_loss: 0.5768 - val_accuracy: 0.8969\nEpoch 87/100\n155/155 [==============================] - 91s 584ms/step - loss: 0.2065 - accuracy: 0.9916 - val_loss: 0.6664 - val_accuracy: 0.8852\nEpoch 88/100\n155/155 [==============================] - 87s 560ms/step - loss: 0.1965 - accuracy: 0.9935 - val_loss: 0.6505 - val_accuracy: 0.8794\nEpoch 89/100\n155/155 [==============================] - 87s 561ms/step - loss: 0.1981 - accuracy: 0.9909 - val_loss: 0.6294 - val_accuracy: 0.8833\nEpoch 90/100\n155/155 [==============================] - 91s 587ms/step - loss: 0.2022 - accuracy: 0.9935 - val_loss: 0.6320 - val_accuracy: 0.8930\nEpoch 91/100\n155/155 [==============================] - 91s 586ms/step - loss: 0.2116 - accuracy: 0.9890 - val_loss: 0.6392 - val_accuracy: 0.8774\nEpoch 92/100\n155/155 [==============================] - 87s 561ms/step - loss: 0.2331 - accuracy: 0.9838 - val_loss: 0.6032 - val_accuracy: 0.8891\nEpoch 93/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.2047 - accuracy: 0.9916 - val_loss: 0.5871 - val_accuracy: 0.8988\nEpoch 94/100\n155/155 [==============================] - 87s 562ms/step - loss: 0.1992 - accuracy: 0.9922 - val_loss: 0.5855 - val_accuracy: 0.8949\nEpoch 95/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.2090 - accuracy: 0.9896 - val_loss: 0.6888 - val_accuracy: 0.8852\nEpoch 96/100\n155/155 [==============================] - 91s 586ms/step - loss: 0.2368 - accuracy: 0.9831 - val_loss: 0.6505 - val_accuracy: 0.8911\nEpoch 97/100\n155/155 [==============================] - 90s 584ms/step - loss: 0.2176 - accuracy: 0.9896 - val_loss: 0.6772 - val_accuracy: 0.8755\nEpoch 98/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.2237 - accuracy: 0.9870 - val_loss: 0.7014 - val_accuracy: 0.8988\nEpoch 99/100\n155/155 [==============================] - 91s 585ms/step - loss: 0.2235 - accuracy: 0.9844 - val_loss: 0.6144 - val_accuracy: 0.8872\nEpoch 100/100\n155/155 [==============================] - 87s 563ms/step - loss: 0.2048 - accuracy: 0.9903 - val_loss: 0.7027 - val_accuracy: 0.8969\n","output_type":"stream"}]},{"cell_type":"code","source":"'''batch_size = 40     # set batch size for training\nepochs = 40         # number of all epochs in training\npatience = 1 \t\t    # number of epochs to wait to adjust lr if monitored value does not improve\nstop_patience = 3 \t# number of epochs to wait before stopping training if monitored value does not improve\nthreshold = 0.9 \t  # if train accuracy is < threshhold adjust monitor accuracy, else monitor validation loss\nfactor = 0.5 \t\t    # factor to reduce lr by\nask_epoch = 5\t\t    # number of epochs to run before asking if you want to halt training\nbatches = int(np.ceil(len(train_gen.labels) / batch_size))'''","metadata":{"execution":{"iopub.status.busy":"2023-06-22T13:25:32.937730Z","iopub.execute_input":"2023-06-22T13:25:32.938476Z","iopub.status.idle":"2023-06-22T13:25:32.947037Z","shell.execute_reply.started":"2023-06-22T13:25:32.938438Z","shell.execute_reply":"2023-06-22T13:25:32.946031Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'batch_size = 40     # set batch size for training\\nepochs = 40         # number of all epochs in training\\npatience = 1 \\t\\t    # number of epochs to wait to adjust lr if monitored value does not improve\\nstop_patience = 3 \\t# number of epochs to wait before stopping training if monitored value does not improve\\nthreshold = 0.9 \\t  # if train accuracy is < threshhold adjust monitor accuracy, else monitor validation loss\\nfactor = 0.5 \\t\\t    # factor to reduce lr by\\nask_epoch = 5\\t\\t    # number of epochs to run before asking if you want to halt training\\nbatches = int(np.ceil(len(train_gen.labels) / batch_size))'"},"metadata":{}}]},{"cell_type":"code","source":"# Load the best weights\n#model.load_weights('/kaggle/working/best_model2.h5')","metadata":{"execution":{"iopub.status.busy":"2023-06-22T13:25:32.948455Z","iopub.execute_input":"2023-06-22T13:25:32.948895Z","iopub.status.idle":"2023-06-22T13:25:32.958738Z","shell.execute_reply.started":"2023-06-22T13:25:32.948858Z","shell.execute_reply":"2023-06-22T13:25:32.957778Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test set\nval_loss, val_accuracy = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Test loss:\", val_loss)\nprint(\"Test accuracy:\", val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T13:26:12.990090Z","iopub.execute_input":"2023-06-22T13:26:12.991224Z","iopub.status.idle":"2023-06-22T13:26:18.674171Z","shell.execute_reply.started":"2023-06-22T13:26:12.991182Z","shell.execute_reply":"2023-06-22T13:26:18.673085Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Test loss: 0.6039268970489502\nTest accuracy: 0.8949416279792786\n","output_type":"stream"}]},{"cell_type":"code","source":"# Plot the training loss and accuracy\nN = len(history.history['loss'])\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"center right\")\nplt.savefig(\"EfficientNet_Model\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training and validation accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\n# Plot the training and validation loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test data\ny_pred = model.predict(x_test)\ny_pred = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_test, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate and plot the confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplot_confusion_matrix(conf_mat=cm, class_names=categories, show_normed=True, figsize=(10, 10))\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the classification report\nreport = classification_report(y_true, y_pred, target_names=categories)\nprint(report)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}