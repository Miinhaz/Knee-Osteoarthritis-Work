{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install efficientnet\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-13T12:58:09.673360Z","iopub.execute_input":"2023-06-13T12:58:09.673687Z","iopub.status.idle":"2023-06-13T12:58:25.378263Z","shell.execute_reply.started":"2023-06-13T12:58:09.673654Z","shell.execute_reply":"2023-06-13T12:58:25.377090Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet) (0.20.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.23.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.8.0)\nRequirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.10.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (3.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (9.5.0)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2.28.1)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2023.4.12)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.4.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (21.3)\nRequirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->scikit-image->efficientnet) (3.0.9)\nInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.1 keras-applications-1.0.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\nimport matplotlib.pyplot as plt\nfrom efficientnet.keras import EfficientNetB3, EfficientNetB4\nfrom keras.applications import InceptionV3","metadata":{"execution":{"iopub.status.busy":"2023-06-13T12:58:25.381261Z","iopub.execute_input":"2023-06-13T12:58:25.381652Z","iopub.status.idle":"2023-06-13T12:58:40.951738Z","shell.execute_reply.started":"2023-06-13T12:58:25.381611Z","shell.execute_reply":"2023-06-13T12:58:40.950801Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the data path and categories\ndata_path = '/kaggle/input/koa-1500/MedicalExpert-I'\ncategories = os.listdir(data_path)\nlabels = [i for i in range(len(categories))]\n\nlabel_dict = dict(zip(categories, labels))\n\nimg_size = 256\ndata = []\nlabel = []\n\n# Load the images and labels\nfor category in categories:\n    folder_path = os.path.join(data_path, category)\n    img_names = os.listdir(folder_path)\n\n    for img_name in img_names:\n        img_path = os.path.join(folder_path, img_name)\n        img = cv2.imread(img_path)\n        try:\n            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            resized = cv2.resize(gray, (img_size, img_size))\n            data.append(resized)\n            label.append(label_dict[category])\n        except Exception as e:\n            print('Exception:', e)\n\ndata = np.array(data) / 255.0\ndata_rgb = np.repeat(data[..., np.newaxis], 3, -1)\nlabel = np.array(label)\nnew_label = np_utils.to_categorical(label)\n\n# Split the data into train, test, and validation sets\nx_train, x_test, y_train, y_test = train_test_split(data_rgb, new_label, test_size=0.2, random_state=42)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.125, random_state=42)\n\n# Define the data generators\ndatagen_train = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.2,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True\n)\n\ndatagen_val = ImageDataGenerator()\n\ntrain_generator = datagen_train.flow_from_directory(\n    '/kaggle/input/koa-1500/MedicalExpert-I/train',\n    target_size=(img_size, img_size),\n    batch_size=32,\n    class_mode='categorical'\n)\n\nval_generator = datagen_val.flow_from_directory(\n    '/kaggle/input/koa-1500/MedicalExpert-I/validation',\n    target_size=(img_size, img_size),\n    batch_size=32,\n    class_mode='categorical'\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-13T13:38:19.959692Z","iopub.execute_input":"2023-06-13T13:38:19.960076Z","iopub.status.idle":"2023-06-13T13:38:28.979292Z","shell.execute_reply.started":"2023-06-13T13:38:19.960046Z","shell.execute_reply":"2023-06-13T13:38:28.977758Z"},"trusted":true},"execution_count":30,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 50\u001b[0m\n\u001b[1;32m     38\u001b[0m datagen_train \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m     39\u001b[0m     rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     40\u001b[0m     zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     vertical_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     48\u001b[0m datagen_val \u001b[38;5;241m=\u001b[39m ImageDataGenerator()\n\u001b[0;32m---> 50\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/koa-1500/MedicalExpert-I/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     55\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m val_generator \u001b[38;5;241m=\u001b[39m datagen_val\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/koa-1500/MedicalExpert-I/validation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     59\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(img_size, img_size),\n\u001b[1;32m     60\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     61\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     62\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:1648\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1564\u001b[0m     directory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1579\u001b[0m ):\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m \n\u001b[1;32m   1582\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;124;03m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m    562\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    565\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/koa-1500/MedicalExpert-I/train'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/koa-1500/MedicalExpert-I/train'","output_type":"error"}]},{"cell_type":"code","source":"# Define the model architecture\nmodel = Sequential()\n\nfrom keras.layers import Input\nfrom keras.layers import Input, GlobalAveragePooling2D,GlobalMaxPooling2D, Dropout, Dense, Reshape\nfrom keras.models import Model\n\n# Define the input shape\ninput_shape = (img_size, img_size, 3)\n\n# EfficientNet B3\nbase_model1 = EfficientNetB3(weights='imagenet', include_top=False, input_shape=input_shape)\n# EfficientNet B5\nbase_model2 = EfficientNetB4(weights='imagenet', include_top=False, input_shape=input_shape)\n# InceptionV3\nbase_model3 = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n\n# Create input tensor\ninput_tensor = Input(shape=input_shape)\n\n# Build the ensemble model\nx1 = base_model1(input_tensor)\nx1 = GlobalAveragePooling2D()(x1)\nx1 = Dropout(0.5)(x1)\nx1 = Dense(1024, activation='relu')(x1)\n\nx2 = base_model2(input_tensor)\nx2 = GlobalAveragePooling2D()(x2)\nx2 = Dropout(0.5)(x2)\nx2 = Dense(1024, activation='relu')(x2)\n\nx3 = base_model3(input_tensor)\nx3 = GlobalMaxPooling2D()(x3)\nx3 = Dense(1024, activation='relu')(x3)\nx3 = Reshape((1, 1, 1024))(x3)  # Reshape the tensor to (1, 1, 1024)\nx3 = Dropout(0.5)(x3)\n\n# Concatenate the outputs of the three models\nx = Dense(len(categories), activation='softmax')(x1 + x2 + x3)\n\n# Create the ensemble model\nmodel = Model(inputs=input_tensor, outputs=x)\n\n# Create the ensemble model\nmodel = Model(inputs=input_tensor, outputs=x)\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-13T13:23:57.351597Z","iopub.execute_input":"2023-06-13T13:23:57.351983Z","iopub.status.idle":"2023-06-13T13:24:11.894815Z","shell.execute_reply.started":"2023-06-13T13:23:57.351936Z","shell.execute_reply":"2023-06-13T13:24:11.893750Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_46 (InputLayer)          [(None, 256, 256, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n efficientnet-b3 (Functional)   (None, 8, 8, 1536)   10783528    ['input_46[0][0]']               \n                                                                                                  \n efficientnet-b4 (Functional)   (None, 8, 8, 1792)   17673816    ['input_46[0][0]']               \n                                                                                                  \n inception_v3 (Functional)      (None, 6, 6, 2048)   21802784    ['input_46[0][0]']               \n                                                                                                  \n global_average_pooling2d_19 (G  (None, 1536)        0           ['efficientnet-b3[0][0]']        \n lobalAveragePooling2D)                                                                           \n                                                                                                  \n global_average_pooling2d_20 (G  (None, 1792)        0           ['efficientnet-b4[0][0]']        \n lobalAveragePooling2D)                                                                           \n                                                                                                  \n global_max_pooling2d_2 (Global  (None, 2048)        0           ['inception_v3[0][0]']           \n MaxPooling2D)                                                                                    \n                                                                                                  \n dropout_20 (Dropout)           (None, 1536)         0           ['global_average_pooling2d_19[0][\n                                                                 0]']                             \n                                                                                                  \n dropout_21 (Dropout)           (None, 1792)         0           ['global_average_pooling2d_20[0][\n                                                                 0]']                             \n                                                                                                  \n dense_9 (Dense)                (None, 1024)         2098176     ['global_max_pooling2d_2[0][0]'] \n                                                                                                  \n dense_7 (Dense)                (None, 1024)         1573888     ['dropout_20[0][0]']             \n                                                                                                  \n dense_8 (Dense)                (None, 1024)         1836032     ['dropout_21[0][0]']             \n                                                                                                  \n reshape_3 (Reshape)            (None, 1, 1, 1024)   0           ['dense_9[0][0]']                \n                                                                                                  \n tf.__operators__.add_5 (TFOpLa  (None, 1024)        0           ['dense_7[0][0]',                \n mbda)                                                            'dense_8[0][0]']                \n                                                                                                  \n dropout_22 (Dropout)           (None, 1, 1, 1024)   0           ['reshape_3[0][0]']              \n                                                                                                  \n tf.__operators__.add_6 (TFOpLa  (None, 1, None, 102  0          ['tf.__operators__.add_5[0][0]', \n mbda)                          4)                                'dropout_22[0][0]']             \n                                                                                                  \n dense_10 (Dense)               (None, 1, None, 5)   5125        ['tf.__operators__.add_6[0][0]'] \n                                                                                                  \n==================================================================================================\nTotal params: 55,773,349\nTrainable params: 55,526,421\nNon-trainable params: 246,928\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set up a checkpoint to save the best model\nfrom keras.callbacks import EarlyStopping\ncheckpoint = ModelCheckpoint('/kaggle/working/model_ensemble.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T13:27:26.547034Z","iopub.execute_input":"2023-06-13T13:27:26.548025Z","iopub.status.idle":"2023-06-13T13:27:26.552560Z","shell.execute_reply.started":"2023-06-13T13:27:26.547983Z","shell.execute_reply":"2023-06-13T13:27:26.551680Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Set up early stopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T13:27:33.025592Z","iopub.execute_input":"2023-06-13T13:27:33.025955Z","iopub.status.idle":"2023-06-13T13:27:33.031191Z","shell.execute_reply.started":"2023-06-13T13:27:33.025925Z","shell.execute_reply":"2023-06-13T13:27:33.030006Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(train_generator,\n                    epochs=90,\n                    validation_data=val_generator,\n                    #callbacks=[checkpoint])\n                    callbacks=[checkpoint, early_stopping])","metadata":{"execution":{"iopub.status.busy":"2023-06-13T13:27:36.795623Z","iopub.execute_input":"2023-06-13T13:27:36.796007Z","iopub.status.idle":"2023-06-13T13:27:42.974999Z","shell.execute_reply.started":"2023-06-13T13:27:36.795956Z","shell.execute_reply":"2023-06-13T13:27:42.973429Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1/90\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m#callbacks=[checkpoint])\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_file0uxlb8ju.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, None) and (None, 1, None, 5) are incompatible\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, None) and (None, 1, None, 5) are incompatible\n","output_type":"error"}]},{"cell_type":"code","source":"# Load the best weights\nmodel.load_weights('/kaggle/working/model_ensemble.h5')","metadata":{"execution":{"iopub.status.busy":"2023-06-13T12:59:20.264245Z","iopub.status.idle":"2023-06-13T12:59:20.265023Z","shell.execute_reply.started":"2023-06-13T12:59:20.264764Z","shell.execute_reply":"2023-06-13T12:59:20.264786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training loss and accuracy\nN = len(history.history['loss'])\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"center right\")\nplt.savefig(\"EfficientNet_Model\")","metadata":{"execution":{"iopub.status.busy":"2023-06-13T12:59:20.266425Z","iopub.status.idle":"2023-06-13T12:59:20.267246Z","shell.execute_reply.started":"2023-06-13T12:59:20.266973Z","shell.execute_reply":"2023-06-13T12:59:20.267008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test set\nval_loss, val_accuracy = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Test loss:\", val_loss)\nprint(\"Test accuracy:\", val_accuracy)\n\n# Get the predictions for the test set\npredictions = model.predict(x_test)\npredicted_labels = np.argmax(predictions, axis=-1)\n\n# Generate the classification report\nreport = classification_report(np.argmax(y_test, axis=1), predicted_labels)\nprint(report)\n\n# Plot the confusion matrix\ntest_labels = np.argmax(y_test, axis=1)\ncm = confusion_matrix(test_labels, predicted_labels)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12, 8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.xticks(range(len(categories)), categories, fontsize=12)\nplt.yticks(range(len(categories)), categories, fontsize=12)\nplt.show()\n\n# Select a single image from the test set for prediction\nX = 32\nimg_single = x_test[X]\nimg_single = cv2.resize(img_single, (img_size, img_size))\nimg_single = np.expand_dims(img_single, 0)\n\n# Make prediction on the single image\npredictions_single = model.predict(img_single)\nprint('A.I predicts:', categories[np.argmax(predictions_single)])\nprint(\"Correct prediction for label\", np.argmax(y_test[X]), 'is', categories[np.argmax(y_test[X])])\n\n# Display the single image\nplt.imshow(np.squeeze(img_single))\nplt.grid(False)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-13T12:59:20.268676Z","iopub.status.idle":"2023-06-13T12:59:20.269444Z","shell.execute_reply.started":"2023-06-13T12:59:20.269194Z","shell.execute_reply":"2023-06-13T12:59:20.269217Z"},"trusted":true},"execution_count":null,"outputs":[]}]}