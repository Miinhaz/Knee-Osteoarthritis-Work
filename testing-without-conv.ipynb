{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1874598,"sourceType":"datasetVersion","datasetId":1115942},{"sourceId":5843182,"sourceType":"datasetVersion","datasetId":3359470},{"sourceId":6476455,"sourceType":"datasetVersion","datasetId":3741302},{"sourceId":6477512,"sourceType":"datasetVersion","datasetId":3742034},{"sourceId":6935927,"sourceType":"datasetVersion","datasetId":3982915},{"sourceId":7274220,"sourceType":"datasetVersion","datasetId":2814684}],"dockerImageVersionId":30498,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install efficientnet\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-19T05:26:56.616865Z","iopub.execute_input":"2024-01-19T05:26:56.617136Z","iopub.status.idle":"2024-01-19T05:27:08.849834Z","shell.execute_reply.started":"2024-01-19T05:26:56.617111Z","shell.execute_reply":"2024-01-19T05:27:08.848734Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet) (0.20.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.23.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.8.0)\nRequirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.10.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (3.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (9.5.0)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2.28.1)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2023.4.12)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.4.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (21.3)\nRequirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->scikit-image->efficientnet) (3.0.9)\nInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.1 keras-applications-1.0.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import ModelCheckpoint, Callback\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom efficientnet.keras import EfficientNetB5\nfrom imblearn.over_sampling import SMOTE","metadata":{"execution":{"iopub.status.busy":"2024-01-19T05:29:39.733481Z","iopub.execute_input":"2024-01-19T05:29:39.734217Z","iopub.status.idle":"2024-01-19T05:29:48.512155Z","shell.execute_reply.started":"2024-01-19T05:29:39.734181Z","shell.execute_reply":"2024-01-19T05:29:48.511355Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"class MyCallback(Callback):\n    def __init__(self, model, patience, stop_patience, threshold, factor, batches, epochs, ask_epoch):\n        super(MyCallback, self).__init__()\n        self.model = model\n        self.patience = patience\n        self.stop_patience = stop_patience\n        self.threshold = threshold\n        self.factor = factor\n        self.batches = batches\n        self.epochs = epochs\n        self.ask_epoch = ask_epoch\n        self.ask_epoch_initial = ask_epoch\n\n        self.count = 0\n        self.stop_count = 0\n        self.best_epoch = 1\n        self.initial_lr = float(tf.keras.backend.get_value(model.optimizer.lr))\n        self.highest_tracc = 0.0\n        self.lowest_vloss = np.inf\n        self.best_weights = self.model.get_weights()\n        self.initial_weights = self.model.get_weights()\n\n    def on_epoch_end(self, epoch, logs=None):\n        if epoch % self.batches == 0 and epoch > 0:\n            tr_acc = logs.get('accuracy')\n            v_loss = logs.get('val_loss')\n\n            if tr_acc > self.highest_tracc:\n                self.highest_tracc = tr_acc\n\n            if v_loss < self.lowest_vloss:\n                self.lowest_vloss = v_loss\n                self.best_epoch = epoch + 1\n                self.best_weights = self.model.get_weights()\n                self.count = 0\n            else:\n                self.count += 1\n\n            if tr_acc >= self.threshold:\n                self.ask_epoch -= 1\n\n            if self.count == self.patience and self.ask_epoch > 0:\n                print(\"\\nEpoch %d: Accuracy threshold reached. Decreasing learning rate.\" % (epoch + 1))\n                old_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n                new_lr = old_lr * self.factor\n                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)\n                print(\"Learning rate decreased from %f to %f\" % (old_lr, new_lr))\n                self.count = 0\n\n            if self.count == self.patience and self.ask_epoch == 0:\n                self.stop_count += 1\n                if self.stop_count == self.stop_patience:\n                    print(\"\\nTraining stopped at epoch %d\" % (epoch + 1))\n                    self.model.stop_training = True\n                else:\n                    print(\"\\nEpoch %d: Learning rate adjustment limit reached. Restoring best weights.\" % (epoch + 1))\n                    self.model.set_weights(self.best_weights)\n                    self.count = 0","metadata":{"execution":{"iopub.status.busy":"2024-01-19T05:30:15.329761Z","iopub.execute_input":"2024-01-19T05:30:15.330384Z","iopub.status.idle":"2024-01-19T05:30:15.343610Z","shell.execute_reply.started":"2024-01-19T05:30:15.330350Z","shell.execute_reply":"2024-01-19T05:30:15.342719Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Set the data path and categories\ndata_path = '/kaggle/input/koa-1500/MedicalExpert-I'\n# List all the categories (subfolders) in the data folder\ncategories = os.listdir(data_path)\n\n# Assign labels to the categories\nlabels = [i for i in range(len(categories))]\n\nlabel_dict = dict(zip(categories, labels))\n\nimg_size = 224\ndata = []\ntarget = []\n\n# Load the image data and labels\nfor category in categories:\n    folder_path = os.path.join(data_path, category)\n    img_names = os.listdir(folder_path)\n\n    for img_name in img_names:\n        img_path = os.path.join(folder_path, img_name)\n        img = cv2.imread(img_path)\n\n        try:\n            # Convert the image to grayscale\n            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            # Convert the grayscale image to RGB by replicating the single channel three times\n            rgb_img = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB)\n            # Resize the image to the desired size\n            resized_img = cv2.resize(rgb_img, (img_size, img_size))\n            # Normalize the image\n            normalized_img = resized_img / 255.0\n            # Append the image and its corresponding label to the data and target lists\n            data.append(normalized_img)\n            target.append(label_dict[category])\n\n        except Exception as e:\n            print('Exception:', e)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T05:30:23.456794Z","iopub.execute_input":"2024-01-19T05:30:23.457172Z","iopub.status.idle":"2024-01-19T05:30:48.911992Z","shell.execute_reply.started":"2024-01-19T05:30:23.457130Z","shell.execute_reply":"2024-01-19T05:30:48.911163Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow-addons\n","metadata":{"execution":{"iopub.status.busy":"2024-01-19T05:30:53.564509Z","iopub.execute_input":"2024-01-19T05:30:53.564921Z","iopub.status.idle":"2024-01-19T05:31:04.301741Z","shell.execute_reply.started":"2024-01-19T05:30:53.564888Z","shell.execute_reply":"2024-01-19T05:31:04.300723Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.10/site-packages (0.20.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons) (21.3)\nRequirement already satisfied: typeguard<3.0.0,>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons) (2.13.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow-addons) (3.0.9)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# Convert the data and target lists to numpy arrays\ndata = np.array(data, dtype='float32')\ntarget = np.array(target)\n\n# Apply SMOTE oversampling to the data\nsmote = SMOTE(random_state=42)\ndata_res, target_res = smote.fit_resample(data.reshape(data.shape[0], -1), target)\ndata_res = data_res.reshape(data_res.shape[0], img_size, img_size, 3)\ntarget_res = np_utils.to_categorical(target_res)\n\n# Split the data into training, validation, and testing sets\nx_train, x_test, y_train, y_test = train_test_split(data_res, target_res, test_size=0.2, random_state=42)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n\nimport tensorflow_addons as tfa\nfrom keras.layers import Dense, Activation, GlobalAveragePooling2D, Dropout, Reshape\n# Construct the EfficientNetB3 model\nbase_model = EfficientNetB5(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3), pooling='max')\n\n# Define the attention layer\nclass AttentionLayer(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(AttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.W_q = self.add_weight(name=\"W_q\", shape=(input_shape[-1], input_shape[-1]), initializer=\"glorot_uniform\", trainable=True)\n        self.W_k = self.add_weight(name=\"W_k\", shape=(input_shape[-1], input_shape[-1]), initializer=\"glorot_uniform\", trainable=True)\n        self.W_v = self.add_weight(name=\"W_v\", shape=(input_shape[-1], input_shape[-1]), initializer=\"glorot_uniform\", trainable=True)\n\n    def call(self, x):\n        q = tf.matmul(x, self.W_q)\n        k = tf.matmul(x, self.W_k)\n        v = tf.matmul(x, self.W_v)\n\n        attn_score = tf.matmul(q, k, transpose_b=True)\n        attn_score = tf.nn.softmax(attn_score, axis=-1)\n\n        output = tf.matmul(attn_score, v)\n        return output\ncategories = 5  # Replace with the actual number of categories\n# Modify your model to include the attention layer\nmodel = Sequential([\n    base_model,\n    Reshape((1, 1, 2048)),\n    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n    AttentionLayer(),  # Add attention layer\n    GlobalAveragePooling2D(),\n    Dense(512, kernel_regularizer=tf.keras.regularizers.l2(l=0.016), activity_regularizer=tf.keras.regularizers.l1(0.006),\n          bias_regularizer=tf.keras.regularizers.l1(0.006), activation='relu'),\n    BatchNormalization(),\n    Dropout(rate=0.45, seed=123),\n    Dense(256, kernel_regularizer=tf.keras.regularizers.l2(l=0.016), activity_regularizer=tf.keras.regularizers.l1(0.006),\n          bias_regularizer=tf.keras.regularizers.l1(0.006), activation='relu'),\n    BatchNormalization(),\n    Dropout(rate=0.45, seed=123),\n    Dense(categories, activation='softmax')\n])\n\nmodel.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-19T06:00:23.739318Z","iopub.execute_input":"2024-01-19T06:00:23.739704Z","iopub.status.idle":"2024-01-19T06:00:43.115540Z","shell.execute_reply.started":"2024-01-19T06:00:23.739673Z","shell.execute_reply":"2024-01-19T06:00:43.114628Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"sequential_4\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnet-b5 (Functional  (None, 2048)             28513520  \n )                                                               \n                                                                 \n reshape_4 (Reshape)         (None, 1, 1, 2048)        0         \n                                                                 \n batch_normalization_18 (Bat  (None, 1, 1, 2048)       8192      \n chNormalization)                                                \n                                                                 \n attention_layer_5 (Attentio  (None, 1, 1, 2048)       12582912  \n nLayer)                                                         \n                                                                 \n global_average_pooling2d_4   (None, 2048)             0         \n (GlobalAveragePooling2D)                                        \n                                                                 \n dense_12 (Dense)            (None, 512)               1049088   \n                                                                 \n batch_normalization_19 (Bat  (None, 512)              2048      \n chNormalization)                                                \n                                                                 \n dropout_8 (Dropout)         (None, 512)               0         \n                                                                 \n dense_13 (Dense)            (None, 256)               131328    \n                                                                 \n batch_normalization_20 (Bat  (None, 256)              1024      \n chNormalization)                                                \n                                                                 \n dropout_9 (Dropout)         (None, 256)               0         \n                                                                 \n dense_14 (Dense)            (None, 5)                 1285      \n                                                                 \n=================================================================\nTotal params: 42,289,397\nTrainable params: 42,111,029\nNon-trainable params: 178,368\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the callbacks\ncheckpoint = ModelCheckpoint('/kaggle/working/best_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\nmy_callback = MyCallback(model=model, patience=10, stop_patience=5, threshold=0.9, factor=0.1, batches=10, epochs=100, ask_epoch=10)\n\n# Train the model\nhistory = model.fit(x_train, y_train, batch_size=16, epochs=100, validation_data=(x_val, y_val), callbacks=[checkpoint, my_callback])","metadata":{"execution":{"iopub.status.busy":"2024-01-19T06:00:55.695694Z","iopub.execute_input":"2024-01-19T06:00:55.696701Z","iopub.status.idle":"2024-01-19T07:12:06.120600Z","shell.execute_reply.started":"2024-01-19T06:00:55.696652Z","shell.execute_reply":"2024-01-19T07:12:06.119683Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-01-19 06:01:39.244094: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_4/efficientnet-b5/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"116/116 [==============================] - ETA: 0s - loss: 22.7712 - accuracy: 0.3795\nEpoch 1: val_accuracy improved from -inf to 0.33495, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 148s 422ms/step - loss: 22.7712 - accuracy: 0.3795 - val_loss: 20.7245 - val_accuracy: 0.3350\nEpoch 2/100\n116/116 [==============================] - ETA: 0s - loss: 20.1504 - accuracy: 0.5249\nEpoch 2: val_accuracy improved from 0.33495 to 0.51942, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 43s 374ms/step - loss: 20.1504 - accuracy: 0.5249 - val_loss: 18.3427 - val_accuracy: 0.5194\nEpoch 3/100\n116/116 [==============================] - ETA: 0s - loss: 17.8955 - accuracy: 0.5773\nEpoch 3: val_accuracy improved from 0.51942 to 0.68932, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 43s 375ms/step - loss: 17.8955 - accuracy: 0.5773 - val_loss: 16.1217 - val_accuracy: 0.6893\nEpoch 4/100\n116/116 [==============================] - ETA: 0s - loss: 15.5846 - accuracy: 0.6243\nEpoch 4: val_accuracy did not improve from 0.68932\n116/116 [==============================] - 41s 353ms/step - loss: 15.5846 - accuracy: 0.6243 - val_loss: 14.1044 - val_accuracy: 0.6650\nEpoch 5/100\n116/116 [==============================] - ETA: 0s - loss: 14.0484 - accuracy: 0.5946\nEpoch 5: val_accuracy improved from 0.68932 to 0.70388, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 43s 371ms/step - loss: 14.0484 - accuracy: 0.5946 - val_loss: 12.7531 - val_accuracy: 0.7039\nEpoch 6/100\n116/116 [==============================] - ETA: 0s - loss: 13.1534 - accuracy: 0.5643\nEpoch 6: val_accuracy improved from 0.70388 to 0.72330, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 43s 375ms/step - loss: 13.1534 - accuracy: 0.5643 - val_loss: 12.2672 - val_accuracy: 0.7233\nEpoch 7/100\n116/116 [==============================] - ETA: 0s - loss: 12.4407 - accuracy: 0.5746\nEpoch 7: val_accuracy did not improve from 0.72330\n116/116 [==============================] - 41s 354ms/step - loss: 12.4407 - accuracy: 0.5746 - val_loss: 11.8649 - val_accuracy: 0.6456\nEpoch 8/100\n116/116 [==============================] - ETA: 0s - loss: 11.9136 - accuracy: 0.5632\nEpoch 8: val_accuracy did not improve from 0.72330\n116/116 [==============================] - 41s 353ms/step - loss: 11.9136 - accuracy: 0.5632 - val_loss: 11.3842 - val_accuracy: 0.6699\nEpoch 9/100\n116/116 [==============================] - ETA: 0s - loss: 11.4093 - accuracy: 0.5514\nEpoch 9: val_accuracy did not improve from 0.72330\n116/116 [==============================] - 41s 355ms/step - loss: 11.4093 - accuracy: 0.5514 - val_loss: 11.0900 - val_accuracy: 0.7184\nEpoch 10/100\n116/116 [==============================] - ETA: 0s - loss: 11.0240 - accuracy: 0.5697\nEpoch 10: val_accuracy improved from 0.72330 to 0.76214, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 43s 372ms/step - loss: 11.0240 - accuracy: 0.5697 - val_loss: 10.3561 - val_accuracy: 0.7621\nEpoch 11/100\n116/116 [==============================] - ETA: 0s - loss: 10.6295 - accuracy: 0.5865\nEpoch 11: val_accuracy improved from 0.76214 to 0.76699, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 44s 376ms/step - loss: 10.6295 - accuracy: 0.5865 - val_loss: 9.9375 - val_accuracy: 0.7670\nEpoch 12/100\n116/116 [==============================] - ETA: 0s - loss: 10.1492 - accuracy: 0.6405\nEpoch 12: val_accuracy improved from 0.76699 to 0.80583, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 43s 374ms/step - loss: 10.1492 - accuracy: 0.6405 - val_loss: 9.5080 - val_accuracy: 0.8058\nEpoch 13/100\n116/116 [==============================] - ETA: 0s - loss: 9.7667 - accuracy: 0.6454\nEpoch 13: val_accuracy did not improve from 0.80583\n116/116 [==============================] - 41s 354ms/step - loss: 9.7667 - accuracy: 0.6454 - val_loss: 9.2616 - val_accuracy: 0.7282\nEpoch 14/100\n116/116 [==============================] - ETA: 0s - loss: 9.4755 - accuracy: 0.6297\nEpoch 14: val_accuracy did not improve from 0.80583\n116/116 [==============================] - 41s 352ms/step - loss: 9.4755 - accuracy: 0.6297 - val_loss: 9.1162 - val_accuracy: 0.7767\nEpoch 15/100\n116/116 [==============================] - ETA: 0s - loss: 9.1565 - accuracy: 0.6335\nEpoch 15: val_accuracy did not improve from 0.80583\n116/116 [==============================] - 41s 351ms/step - loss: 9.1565 - accuracy: 0.6335 - val_loss: 8.9206 - val_accuracy: 0.8010\nEpoch 16/100\n116/116 [==============================] - ETA: 0s - loss: 8.7197 - accuracy: 0.6681\nEpoch 16: val_accuracy did not improve from 0.80583\n116/116 [==============================] - 41s 352ms/step - loss: 8.7197 - accuracy: 0.6681 - val_loss: 8.6050 - val_accuracy: 0.7767\nEpoch 17/100\n116/116 [==============================] - ETA: 0s - loss: 8.3142 - accuracy: 0.6978\nEpoch 17: val_accuracy did not improve from 0.80583\n116/116 [==============================] - 41s 354ms/step - loss: 8.3142 - accuracy: 0.6978 - val_loss: 7.9917 - val_accuracy: 0.7718\nEpoch 18/100\n116/116 [==============================] - ETA: 0s - loss: 8.0145 - accuracy: 0.6816\nEpoch 18: val_accuracy did not improve from 0.80583\n116/116 [==============================] - 41s 353ms/step - loss: 8.0145 - accuracy: 0.6816 - val_loss: 7.6757 - val_accuracy: 0.7767\nEpoch 19/100\n116/116 [==============================] - ETA: 0s - loss: 7.6370 - accuracy: 0.7027\nEpoch 19: val_accuracy did not improve from 0.80583\n116/116 [==============================] - 41s 352ms/step - loss: 7.6370 - accuracy: 0.7027 - val_loss: 7.2852 - val_accuracy: 0.8010\nEpoch 20/100\n116/116 [==============================] - ETA: 0s - loss: 7.3952 - accuracy: 0.6681\nEpoch 20: val_accuracy did not improve from 0.80583\n116/116 [==============================] - 41s 353ms/step - loss: 7.3952 - accuracy: 0.6681 - val_loss: 6.9990 - val_accuracy: 0.7670\nEpoch 21/100\n116/116 [==============================] - ETA: 0s - loss: 6.9958 - accuracy: 0.6957\nEpoch 21: val_accuracy improved from 0.80583 to 0.83495, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 43s 375ms/step - loss: 6.9958 - accuracy: 0.6957 - val_loss: 6.5717 - val_accuracy: 0.8350\nEpoch 22/100\n116/116 [==============================] - ETA: 0s - loss: 6.7119 - accuracy: 0.6941\nEpoch 22: val_accuracy did not improve from 0.83495\n116/116 [==============================] - 41s 351ms/step - loss: 6.7119 - accuracy: 0.6941 - val_loss: 6.3366 - val_accuracy: 0.7816\nEpoch 23/100\n116/116 [==============================] - ETA: 0s - loss: 6.3294 - accuracy: 0.7297\nEpoch 23: val_accuracy improved from 0.83495 to 0.85437, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 43s 375ms/step - loss: 6.3294 - accuracy: 0.7297 - val_loss: 5.9038 - val_accuracy: 0.8544\nEpoch 24/100\n116/116 [==============================] - ETA: 0s - loss: 6.0361 - accuracy: 0.7119\nEpoch 24: val_accuracy did not improve from 0.85437\n116/116 [==============================] - 41s 354ms/step - loss: 6.0361 - accuracy: 0.7119 - val_loss: 5.6588 - val_accuracy: 0.8398\nEpoch 25/100\n116/116 [==============================] - ETA: 0s - loss: 5.6658 - accuracy: 0.7384\nEpoch 25: val_accuracy did not improve from 0.85437\n116/116 [==============================] - 41s 356ms/step - loss: 5.6658 - accuracy: 0.7384 - val_loss: 5.5346 - val_accuracy: 0.7476\nEpoch 26/100\n116/116 [==============================] - ETA: 0s - loss: 5.3846 - accuracy: 0.7373\nEpoch 26: val_accuracy did not improve from 0.85437\n116/116 [==============================] - 41s 353ms/step - loss: 5.3846 - accuracy: 0.7373 - val_loss: 5.0413 - val_accuracy: 0.8058\nEpoch 27/100\n116/116 [==============================] - ETA: 0s - loss: 5.0203 - accuracy: 0.7735\nEpoch 27: val_accuracy improved from 0.85437 to 0.87379, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 43s 372ms/step - loss: 5.0203 - accuracy: 0.7735 - val_loss: 4.8611 - val_accuracy: 0.8738\nEpoch 28/100\n116/116 [==============================] - ETA: 0s - loss: 4.7966 - accuracy: 0.7568\nEpoch 28: val_accuracy did not improve from 0.87379\n116/116 [==============================] - 41s 353ms/step - loss: 4.7966 - accuracy: 0.7568 - val_loss: 4.3720 - val_accuracy: 0.8592\nEpoch 29/100\n116/116 [==============================] - ETA: 0s - loss: 4.4413 - accuracy: 0.7681\nEpoch 29: val_accuracy did not improve from 0.87379\n116/116 [==============================] - 41s 352ms/step - loss: 4.4413 - accuracy: 0.7681 - val_loss: 4.1214 - val_accuracy: 0.8689\nEpoch 30/100\n116/116 [==============================] - ETA: 0s - loss: 4.1380 - accuracy: 0.7800\nEpoch 30: val_accuracy improved from 0.87379 to 0.88835, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 43s 374ms/step - loss: 4.1380 - accuracy: 0.7800 - val_loss: 3.8552 - val_accuracy: 0.8883\nEpoch 31/100\n116/116 [==============================] - ETA: 0s - loss: 3.8905 - accuracy: 0.7957\nEpoch 31: val_accuracy did not improve from 0.88835\n116/116 [==============================] - 41s 354ms/step - loss: 3.8905 - accuracy: 0.7957 - val_loss: 3.6164 - val_accuracy: 0.8592\nEpoch 32/100\n116/116 [==============================] - ETA: 0s - loss: 3.6927 - accuracy: 0.7870\nEpoch 32: val_accuracy did not improve from 0.88835\n116/116 [==============================] - 41s 352ms/step - loss: 3.6927 - accuracy: 0.7870 - val_loss: 3.4471 - val_accuracy: 0.8350\nEpoch 33/100\n116/116 [==============================] - ETA: 0s - loss: 3.3854 - accuracy: 0.8189\nEpoch 33: val_accuracy did not improve from 0.88835\n116/116 [==============================] - 41s 352ms/step - loss: 3.3854 - accuracy: 0.8189 - val_loss: 3.0939 - val_accuracy: 0.8641\nEpoch 34/100\n116/116 [==============================] - ETA: 0s - loss: 3.1561 - accuracy: 0.8173\nEpoch 34: val_accuracy did not improve from 0.88835\n116/116 [==============================] - 41s 354ms/step - loss: 3.1561 - accuracy: 0.8173 - val_loss: 2.8824 - val_accuracy: 0.8689\nEpoch 35/100\n116/116 [==============================] - ETA: 0s - loss: 2.8819 - accuracy: 0.8276\nEpoch 35: val_accuracy did not improve from 0.88835\n116/116 [==============================] - 41s 354ms/step - loss: 2.8819 - accuracy: 0.8276 - val_loss: 2.6811 - val_accuracy: 0.8689\nEpoch 36/100\n116/116 [==============================] - ETA: 0s - loss: 2.6884 - accuracy: 0.8276\nEpoch 36: val_accuracy improved from 0.88835 to 0.91262, saving model to /kaggle/working/best_model.h5\n116/116 [==============================] - 43s 374ms/step - loss: 2.6884 - accuracy: 0.8276 - val_loss: 2.4674 - val_accuracy: 0.9126\nEpoch 37/100\n116/116 [==============================] - ETA: 0s - loss: 2.5118 - accuracy: 0.8249\nEpoch 37: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 2.5118 - accuracy: 0.8249 - val_loss: 2.3273 - val_accuracy: 0.8883\nEpoch 38/100\n116/116 [==============================] - ETA: 0s - loss: 2.3274 - accuracy: 0.8373\nEpoch 38: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 2.3274 - accuracy: 0.8373 - val_loss: 2.1866 - val_accuracy: 0.8786\nEpoch 39/100\n116/116 [==============================] - ETA: 0s - loss: 2.1225 - accuracy: 0.8503\nEpoch 39: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 350ms/step - loss: 2.1225 - accuracy: 0.8503 - val_loss: 2.1092 - val_accuracy: 0.8495\nEpoch 40/100\n116/116 [==============================] - ETA: 0s - loss: 2.0140 - accuracy: 0.8508\nEpoch 40: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 2.0140 - accuracy: 0.8508 - val_loss: 1.9217 - val_accuracy: 0.8495\nEpoch 41/100\n116/116 [==============================] - ETA: 0s - loss: 1.8611 - accuracy: 0.8530\nEpoch 41: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 354ms/step - loss: 1.8611 - accuracy: 0.8530 - val_loss: 1.7818 - val_accuracy: 0.8689\nEpoch 42/100\n116/116 [==============================] - ETA: 0s - loss: 1.7440 - accuracy: 0.8443\nEpoch 42: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 1.7440 - accuracy: 0.8443 - val_loss: 1.6451 - val_accuracy: 0.8689\nEpoch 43/100\n116/116 [==============================] - ETA: 0s - loss: 1.5571 - accuracy: 0.8724\nEpoch 43: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 1.5571 - accuracy: 0.8724 - val_loss: 1.4533 - val_accuracy: 0.8932\nEpoch 44/100\n116/116 [==============================] - ETA: 0s - loss: 1.4765 - accuracy: 0.8789\nEpoch 44: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 1.4765 - accuracy: 0.8789 - val_loss: 1.4169 - val_accuracy: 0.8786\nEpoch 45/100\n116/116 [==============================] - ETA: 0s - loss: 1.3376 - accuracy: 0.8903\nEpoch 45: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 1.3376 - accuracy: 0.8903 - val_loss: 1.2899 - val_accuracy: 0.8932\nEpoch 46/100\n116/116 [==============================] - ETA: 0s - loss: 1.2640 - accuracy: 0.8914\nEpoch 46: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 353ms/step - loss: 1.2640 - accuracy: 0.8914 - val_loss: 1.1842 - val_accuracy: 0.9078\nEpoch 47/100\n116/116 [==============================] - ETA: 0s - loss: 1.2197 - accuracy: 0.8714\nEpoch 47: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 1.2197 - accuracy: 0.8714 - val_loss: 1.1798 - val_accuracy: 0.8738\nEpoch 48/100\n116/116 [==============================] - ETA: 0s - loss: 1.1502 - accuracy: 0.8870\nEpoch 48: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 1.1502 - accuracy: 0.8870 - val_loss: 1.0353 - val_accuracy: 0.9078\nEpoch 49/100\n116/116 [==============================] - ETA: 0s - loss: 1.0298 - accuracy: 0.9027\nEpoch 49: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 1.0298 - accuracy: 0.9027 - val_loss: 1.0015 - val_accuracy: 0.8786\nEpoch 50/100\n116/116 [==============================] - ETA: 0s - loss: 1.0294 - accuracy: 0.8854\nEpoch 50: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 1.0294 - accuracy: 0.8854 - val_loss: 0.9403 - val_accuracy: 0.8981\nEpoch 51/100\n116/116 [==============================] - ETA: 0s - loss: 0.8717 - accuracy: 0.9065\nEpoch 52: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 356ms/step - loss: 0.8717 - accuracy: 0.9065 - val_loss: 0.9881 - val_accuracy: 0.8932\nEpoch 53/100\n116/116 [==============================] - ETA: 0s - loss: 0.8610 - accuracy: 0.8957\nEpoch 53: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 354ms/step - loss: 0.8610 - accuracy: 0.8957 - val_loss: 0.9000 - val_accuracy: 0.8786\nEpoch 54/100\n116/116 [==============================] - ETA: 0s - loss: 0.7991 - accuracy: 0.8978\nEpoch 54: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.7991 - accuracy: 0.8978 - val_loss: 0.8195 - val_accuracy: 0.8932\nEpoch 55/100\n116/116 [==============================] - ETA: 0s - loss: 0.7675 - accuracy: 0.9038\nEpoch 55: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 353ms/step - loss: 0.7675 - accuracy: 0.9038 - val_loss: 0.7942 - val_accuracy: 0.8835\nEpoch 56/100\n116/116 [==============================] - ETA: 0s - loss: 0.7072 - accuracy: 0.9103\nEpoch 56: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.7072 - accuracy: 0.9103 - val_loss: 0.8645 - val_accuracy: 0.8544\nEpoch 57/100\n116/116 [==============================] - ETA: 0s - loss: 0.6877 - accuracy: 0.9092\nEpoch 57: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 40s 346ms/step - loss: 0.6877 - accuracy: 0.9092 - val_loss: 0.8734 - val_accuracy: 0.8544\nEpoch 58/100\n116/116 [==============================] - ETA: 0s - loss: 0.7375 - accuracy: 0.8892\nEpoch 58: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 40s 345ms/step - loss: 0.7375 - accuracy: 0.8892 - val_loss: 0.7543 - val_accuracy: 0.8592\nEpoch 59/100\n116/116 [==============================] - ETA: 0s - loss: 0.6104 - accuracy: 0.9227\nEpoch 59: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 353ms/step - loss: 0.6104 - accuracy: 0.9227 - val_loss: 0.7746 - val_accuracy: 0.8883\nEpoch 60/100\n116/116 [==============================] - ETA: 0s - loss: 0.5808 - accuracy: 0.9270\nEpoch 60: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 354ms/step - loss: 0.5808 - accuracy: 0.9270 - val_loss: 0.6973 - val_accuracy: 0.9078\nEpoch 61/100\n116/116 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.9200\nEpoch 61: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.5859 - accuracy: 0.9200 - val_loss: 0.7698 - val_accuracy: 0.8592\nEpoch 62/100\n116/116 [==============================] - ETA: 0s - loss: 0.5413 - accuracy: 0.9308\nEpoch 62: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.5413 - accuracy: 0.9308 - val_loss: 0.7261 - val_accuracy: 0.8786\nEpoch 63/100\n116/116 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.9227\nEpoch 63: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.5451 - accuracy: 0.9227 - val_loss: 0.6742 - val_accuracy: 0.9029\nEpoch 64/100\n116/116 [==============================] - ETA: 0s - loss: 0.5276 - accuracy: 0.9368\nEpoch 64: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.5276 - accuracy: 0.9368 - val_loss: 0.7046 - val_accuracy: 0.8932\nEpoch 65/100\n116/116 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.9432\nEpoch 65: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.5094 - accuracy: 0.9432 - val_loss: 0.7873 - val_accuracy: 0.8786\nEpoch 66/100\n116/116 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.9303\nEpoch 66: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.5046 - accuracy: 0.9303 - val_loss: 0.6744 - val_accuracy: 0.8932\nEpoch 67/100\n116/116 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.9459\nEpoch 67: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.4443 - accuracy: 0.9459 - val_loss: 0.6329 - val_accuracy: 0.8786\nEpoch 68/100\n116/116 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.9362\nEpoch 68: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.4748 - accuracy: 0.9362 - val_loss: 0.6828 - val_accuracy: 0.8786\nEpoch 69/100\n116/116 [==============================] - ETA: 0s - loss: 0.4698 - accuracy: 0.9357\nEpoch 69: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.4698 - accuracy: 0.9357 - val_loss: 0.7862 - val_accuracy: 0.8592\nEpoch 70/100\n116/116 [==============================] - ETA: 0s - loss: 0.5037 - accuracy: 0.9297\nEpoch 70: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.5037 - accuracy: 0.9297 - val_loss: 0.8243 - val_accuracy: 0.8447\nEpoch 71/100\n116/116 [==============================] - ETA: 0s - loss: 0.4863 - accuracy: 0.9308\nEpoch 71: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.4863 - accuracy: 0.9308 - val_loss: 0.6841 - val_accuracy: 0.8786\nEpoch 72/100\n116/116 [==============================] - ETA: 0s - loss: 0.4559 - accuracy: 0.9292\nEpoch 72: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 350ms/step - loss: 0.4559 - accuracy: 0.9292 - val_loss: 0.7912 - val_accuracy: 0.8689\nEpoch 73/100\n116/116 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.9297\nEpoch 73: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.4548 - accuracy: 0.9297 - val_loss: 0.6080 - val_accuracy: 0.8738\nEpoch 74/100\n116/116 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.9330\nEpoch 74: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.4291 - accuracy: 0.9330 - val_loss: 0.6583 - val_accuracy: 0.8641\nEpoch 75/100\n116/116 [==============================] - ETA: 0s - loss: 0.4260 - accuracy: 0.9373\nEpoch 75: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.4260 - accuracy: 0.9373 - val_loss: 0.6044 - val_accuracy: 0.9126\nEpoch 76/100\n116/116 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.9043\nEpoch 76: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.4915 - accuracy: 0.9043 - val_loss: 0.6394 - val_accuracy: 0.8932\nEpoch 77/100\n116/116 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.9303\nEpoch 77: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 354ms/step - loss: 0.4316 - accuracy: 0.9303 - val_loss: 0.6027 - val_accuracy: 0.8544\nEpoch 78/100\n116/116 [==============================] - ETA: 0s - loss: 0.4026 - accuracy: 0.9351\nEpoch 78: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.4026 - accuracy: 0.9351 - val_loss: 0.6308 - val_accuracy: 0.8689\nEpoch 79/100\n116/116 [==============================] - ETA: 0s - loss: 0.4136 - accuracy: 0.9357\nEpoch 79: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 353ms/step - loss: 0.4136 - accuracy: 0.9357 - val_loss: 0.8065 - val_accuracy: 0.8641\nEpoch 80/100\n116/116 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.9319\nEpoch 80: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.4526 - accuracy: 0.9319 - val_loss: 0.6252 - val_accuracy: 0.9078\nEpoch 81/100\n116/116 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.9557\nEpoch 81: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 353ms/step - loss: 0.3511 - accuracy: 0.9557 - val_loss: 0.5683 - val_accuracy: 0.8981\nEpoch 82/100\n116/116 [==============================] - ETA: 0s - loss: 0.4196 - accuracy: 0.9330\nEpoch 82: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.4196 - accuracy: 0.9330 - val_loss: 0.5658 - val_accuracy: 0.8835\nEpoch 83/100\n116/116 [==============================] - ETA: 0s - loss: 0.4066 - accuracy: 0.9368\nEpoch 83: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.4066 - accuracy: 0.9368 - val_loss: 0.6167 - val_accuracy: 0.8495\nEpoch 84/100\n116/116 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.9416\nEpoch 84: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.3605 - accuracy: 0.9416 - val_loss: 0.7231 - val_accuracy: 0.8495\nEpoch 85/100\n116/116 [==============================] - ETA: 0s - loss: 0.4178 - accuracy: 0.9378\nEpoch 85: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.4178 - accuracy: 0.9378 - val_loss: 0.6646 - val_accuracy: 0.8689\nEpoch 86/100\n116/116 [==============================] - ETA: 0s - loss: 0.4145 - accuracy: 0.9227\nEpoch 86: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.4145 - accuracy: 0.9227 - val_loss: 0.6273 - val_accuracy: 0.8738\nEpoch 87/100\n116/116 [==============================] - ETA: 0s - loss: 0.3535 - accuracy: 0.9454\nEpoch 87: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.3535 - accuracy: 0.9454 - val_loss: 0.7666 - val_accuracy: 0.8301\nEpoch 88/100\n116/116 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.9486\nEpoch 88: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 355ms/step - loss: 0.3415 - accuracy: 0.9486 - val_loss: 0.6723 - val_accuracy: 0.8495\nEpoch 89/100\n116/116 [==============================] - ETA: 0s - loss: 0.3519 - accuracy: 0.9432\nEpoch 89: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 354ms/step - loss: 0.3519 - accuracy: 0.9432 - val_loss: 0.8189 - val_accuracy: 0.8495\nEpoch 90/100\n116/116 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.9497\nEpoch 90: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.3001 - accuracy: 0.9497 - val_loss: 0.7795 - val_accuracy: 0.8544\nEpoch 91/100\n116/116 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.9427\nEpoch 91: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 353ms/step - loss: 0.3895 - accuracy: 0.9427 - val_loss: 0.4950 - val_accuracy: 0.8981\nEpoch 92/100\n116/116 [==============================] - ETA: 0s - loss: 0.2975 - accuracy: 0.9670\nEpoch 92: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 353ms/step - loss: 0.2975 - accuracy: 0.9670 - val_loss: 0.5942 - val_accuracy: 0.8786\nEpoch 93/100\n116/116 [==============================] - ETA: 0s - loss: 0.3193 - accuracy: 0.9600\nEpoch 93: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.3193 - accuracy: 0.9600 - val_loss: 0.5025 - val_accuracy: 0.9029\nEpoch 94/100\n116/116 [==============================] - ETA: 0s - loss: 0.3420 - accuracy: 0.9351\nEpoch 94: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 353ms/step - loss: 0.3420 - accuracy: 0.9351 - val_loss: 0.6727 - val_accuracy: 0.8495\nEpoch 95/100\n116/116 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.9578\nEpoch 95: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 353ms/step - loss: 0.3026 - accuracy: 0.9578 - val_loss: 0.9939 - val_accuracy: 0.8981\nEpoch 96/100\n116/116 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.9573\nEpoch 96: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 351ms/step - loss: 0.3169 - accuracy: 0.9573 - val_loss: 0.7599 - val_accuracy: 0.8641\nEpoch 97/100\n116/116 [==============================] - ETA: 0s - loss: 0.3299 - accuracy: 0.9530\nEpoch 97: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 354ms/step - loss: 0.3299 - accuracy: 0.9530 - val_loss: 0.6823 - val_accuracy: 0.8932\nEpoch 98/100\n116/116 [==============================] - ETA: 0s - loss: 0.3581 - accuracy: 0.9486\nEpoch 98: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 350ms/step - loss: 0.3581 - accuracy: 0.9486 - val_loss: 0.5453 - val_accuracy: 0.8786\nEpoch 99/100\n116/116 [==============================] - ETA: 0s - loss: 0.2652 - accuracy: 0.9665\nEpoch 99: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 352ms/step - loss: 0.2652 - accuracy: 0.9665 - val_loss: 0.5411 - val_accuracy: 0.8641\nEpoch 100/100\n116/116 [==============================] - ETA: 0s - loss: 0.3036 - accuracy: 0.9541\nEpoch 100: val_accuracy did not improve from 0.91262\n116/116 [==============================] - 41s 350ms/step - loss: 0.3036 - accuracy: 0.9541 - val_loss: 0.5905 - val_accuracy: 0.8592\n","output_type":"stream"}]},{"cell_type":"code","source":"'''batch_size = 40     # set batch size for training\nepochs = 40         # number of all epochs in training\npatience = 1 \t\t    # number of epochs to wait to adjust lr if monitored value does not improve\nstop_patience = 3 \t# number of epochs to wait before stopping training if monitored value does not improve\nthreshold = 0.9 \t  # if train accuracy is < threshhold adjust monitor accuracy, else monitor validation loss\nfactor = 0.5 \t\t    # factor to reduce lr by\nask_epoch = 5\t\t    # number of epochs to run before asking if you want to halt training\nbatches = int(np.ceil(len(train_gen.labels) / batch_size))'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the best weights\nmodel.load_weights('/kaggle/working/best_model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:12:39.649398Z","iopub.execute_input":"2024-01-19T07:12:39.649784Z","iopub.status.idle":"2024-01-19T07:12:40.303550Z","shell.execute_reply.started":"2024-01-19T07:12:39.649753Z","shell.execute_reply":"2024-01-19T07:12:40.302583Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test set\nval_loss, val_accuracy = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Test loss:\", val_loss)\nprint(\"Test accuracy:\", val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:12:52.970275Z","iopub.execute_input":"2024-01-19T07:12:52.971136Z","iopub.status.idle":"2024-01-19T07:12:56.505303Z","shell.execute_reply.started":"2024-01-19T07:12:52.971100Z","shell.execute_reply":"2024-01-19T07:12:56.504317Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Test loss: 2.549952268600464\nTest accuracy: 0.8579766750335693\n","output_type":"stream"}]},{"cell_type":"code","source":"# Plot the training loss and accuracy\nN = len(history.history['loss'])\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"center right\")\nplt.savefig(\"EfficientNet_Model\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:13:01.967931Z","iopub.execute_input":"2024-01-19T07:13:01.968701Z","iopub.status.idle":"2024-01-19T07:13:02.410981Z","shell.execute_reply.started":"2024-01-19T07:13:01.968668Z","shell.execute_reply":"2024-01-19T07:13:02.410046Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Plot the training and validation accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\n# Plot the training and validation loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test data\ny_pred = model.predict(x_test)\ny_pred = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_test, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n# Generate and plot the confusion matrix with 'inferno' colormap using seaborn\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(10, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='inferno', cbar=False,\n            xticklabels=categories, yticklabels=categories, annot_kws={\"size\": 10})\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate and plot the confusion matrix with 'inferno' colormap using seaborn\ncm = confusion_matrix(y_true, y_pred)\nclass_names = ['Doubtful', 'Moderate', 'Severe', 'Mild', 'Normal']\nplt.figure(figsize=(10, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='inferno', cbar=False,\n            xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 10})\nplt.title('Confusion Matrix')\n# Save the figure as a PDF\nplt.savefig('conf.pdf', format='pdf', bbox_inches='tight')\n\n# Show the plot\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the classification report\nreport = classification_report(y_true, y_pred, target_names=categories)\nprint(report)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of images before SMOTE:\", data.shape[0])\nprint(\"Number of images after SMOTE:\", data_res.shape[0])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n# Print class distribution before and after SMOTE\nprint(\"Class distribution before SMOTE:\")\nprint(pd.Series(target).value_counts())\n\nprint(\"\\nClass distribution after SMOTE:\")\nprint(pd.Series(np.argmax(target_res, axis=1)).value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\n# Function to plot better-looking accuracy and loss curves\ndef plot_curves(history, metric, title, ylabel, legend_loc='upper right'):\n    plt.figure(figsize=(12, 6))\n    sns.set(style=\"whitegrid\")\n    \n    plt.plot(history.history[metric], label=f'Training {metric}', linewidth=2)\n    plt.plot(history.history[f'val_{metric}'], label=f'Validation {metric}', linewidth=2)\n\n    plt.title(title)\n    plt.xlabel('Epoch 100')\n    plt.ylabel(ylabel)\n    plt.legend(loc='center right')\n    plt.grid(True)\n    \n    # Save the figure as a PDF\n    plt.savefig('_training_plot.pdf', format='pdf', bbox_inches='tight')\n\n    # Show the plot\n    plt.show()\n\n# Plot the better-looking training and validation accuracy curves\nplot_curves(history, 'accuracy', 'Model Accuracy', 'Accuracy')\n\n# Plot the better-looking training and validation loss curves\nplot_curves(history, 'loss', 'Model Loss', 'Loss')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\n# Function to plot better-looking confusion matrix\ndef plot_confusion_matrix(cm, class_names, normalize=True, figsize=(10, 10)):\n    plt.figure(figsize=figsize)\n    fmt = '.2f' if normalize else 'd'\n    \n    sns.set(font_scale=1.2)\n    sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues', cbar=False,\n                xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 10})\n    \n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('True Labels')\n    plt.show()\n\n# Generate and plot the better-looking confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplot_confusion_matrix(cm, class_names=categories)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom itertools import cycle\n\n# Convert labels to binary format for ROC curve\ny_test_bin = label_binarize(y_true, classes=np.arange(len(categories)))\n\n# Make predictions on the test data\ny_pred_proba = model.predict(x_test)\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(len(categories)):\n    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(10, 10))\n\ncolors = cycle(['blue', 'orange', 'green', 'red', 'purple'])\nfor i, color in zip(range(len(categories)), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f'ROC curve (area = {roc_auc[i]:.2f}) for {categories[i]}')\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom itertools import cycle\n\n# Convert labels to binary format for ROC curve\ny_test_bin = label_binarize(y_true, classes=np.arange(len(categories)))\n\n# Make predictions on the test data\ny_pred_proba = model.predict(x_test)\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(len(categories)):\n    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(10, 10))\n\nclass_names = ['Doubtful', 'Moderate', 'Severe', 'Mild', 'Normal']\ncolors = cycle(['blue', 'orange', 'green', 'red', 'purple'])\nfor i, color in zip(range(len(categories)), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f'ROC curve (AUC = {roc_auc[i]:.2f}) for {class_names[i]}')\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\n# Save the figure as a PDF\nplt.savefig('roc.pdf', format='pdf', bbox_inches='tight')\n\n# Show the plot\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tf_explain\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom PIL import Image\nimport tensorflow as tf\nimport matplotlib.cm as cm\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import ModelCheckpoint, Callback\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom imblearn.over_sampling import SMOTE\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tf_explain.core.grad_cam import GradCAM\nfrom tf_explain.core.grad_cam import GradCAM\n\n# ... (Your existing code for model training and evaluation)\n\n# Now, let's integrate Grad-CAM into your script\n\n# Choose a random image from the test set\nindex = np.random.randint(len(x_test))\nsample_image = x_test[index]\nlabel = np.argmax(y_test[index])\n\n# Display the original image\nplt.imshow(sample_image)\nplt.title(\"Original Image\")\nplt.axis(\"off\")\nplt.show()\n\n# Preprocess the image for prediction\nsample_image = img_to_array(sample_image)\nsample_image = preprocess_input(sample_image)\nsample_image = np.expand_dims(sample_image, axis=0)\n\n# Perform prediction\npredictions = model.predict(sample_image)\npredicted_class_index = np.argmax(predictions[0])\npredicted_class = categories[predicted_class_index]\n\n# Print the predicted class and the true class\ntrue_class = categories[label]\nprint(\"True class:\", true_class)\nprint(\"Predicted class:\", predicted_class)\n\n# Generate Grad-CAM heatmap\nexplainer = GradCAM()\ngradcam = explainer.explain((sample_image, None), model, predicted_class_index)\nheatmap = cv2.resize(gradcam[0], (sample_image.shape[2], sample_image.shape[1]))\n\n# Convert the heatmap to RGB\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n# Convert sample_image[0] to uint8\nsample_image_uint8 = cv2.convertScaleAbs(sample_image[0] * 255.0)\n\n# Superimpose the heatmap on the original image\nsuperimposed_img = cv2.addWeighted(sample_image_uint8, 0.6, heatmap, 0.4, 0)\n\n# Plot the original image, heatmap, and superimposed image\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\naxes[0].imshow(sample_image_uint8)\naxes[0].set_title('Original Image')\n\naxes[1].imshow(heatmap)\naxes[1].set_title('Grad-CAM Heatmap')\n\naxes[2].imshow(superimposed_img)\naxes[2].set_title('Superimposed Image')\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}